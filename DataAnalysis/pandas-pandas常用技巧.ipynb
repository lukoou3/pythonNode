{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 布尔索引\n",
    "如果需要以其它列数据值为条件过滤某一列的数据，您会怎么处理？例如建立一个列表，列表中全部为未能毕业但曾获得贷款的女性。这里可以使用布尔索引，代码如下：\n",
    "```python\n",
    "data.loc[(data[\"Gender\"]==\"Female\") & (data[\"Education\"]==\"Not Graduate\") & (data[\"Loan_Status\"]==\"Y\"), \n",
    "[\"Gender\",\"Education\",\"Loan_Status\"]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loc、iloc操作多行rows，多列columns\n",
    "loc方法\n",
    "```python\n",
    "dataframe.loc[ index,  columns]\n",
    "dataframe.loc[ [index1, index2],  :]\n",
    "dataframe.loc[ :,  columns]\n",
    "```\n",
    "\n",
    "iloc方法\n",
    "```python\n",
    "dataframe.loc[ pos,  columns]\n",
    "dataframe.loc[ [1,2,3],  :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply、applymap、map方法\n",
    "在pandas中， apply() 方法使用是非常灵活的，他比 agg() 方法使用更自由。数据分析师日常使用最多的就是 apply() 方法了，而与之类似的还有 applymap() 和 map() 方法，因此本文将详细介绍下这三种方法的使用和区别：\n",
    "\n",
    "* apply：应用在DataFrame的行或列中；  \n",
    "* applymap：应用在DataFrame的每个元素中；  \n",
    "* map：应用在单独一列（Series）的每个元素中。\n",
    "\n",
    "Apply 函数是处理数据和建立新变量的常用函数之一。在向数据框的每一行或每一列传递指定函数后，Apply 函数会返回相应的值。这个由 Apply 传入的函数可以是系统默认的或者用户自定义的。例如，在下面的例子中它可以用于查找每一行和每一列中的缺失值\n",
    "```python\n",
    "#Create a new function:\n",
    "def num_missing(x):\n",
    "  return sum(x.isnull())\n",
    " \n",
    "#Applying per column:\n",
    "print \"Missing values per column:\"\n",
    "print data.apply(num_missing, axis=0) #axis=0 defines that function is to be applied on each column\n",
    " \n",
    "#Applying per row:\n",
    "print \"nMissing values per row:\"\n",
    "print data.apply(num_missing, axis=1).head() #axis=1 defines that function is to be applied on each row\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何处理缺失数据\n",
    "主要方法有：\n",
    "\n",
    "* isnull()和isna()  \n",
    "* notnull()和notna()  \n",
    "* dropna()  \n",
    "* fillna()  \n",
    "\n",
    "### 判断数据是否缺失\n",
    "使用isnull()函数，返回bool类型数据\n",
    "```\n",
    "dataframe.isnull()\n",
    "```\n",
    "使用notnull()函数，同样返回bool类型数据\n",
    "```\n",
    "dataframe.notnull()\n",
    "```\n",
    "使用sum()函数，统计缺失数据\n",
    "```\n",
    "dataframe.isnull().sum()\n",
    "```\n",
    "\n",
    "### 过滤缺失数据\n",
    "```\n",
    "dataframe[dataframe.colname.isnull()]\n",
    "dataframe[dataframe.colname.notnull()]\n",
    "```\n",
    "\n",
    "### 丢弃缺失数据\n",
    "how按行row判断\n",
    "```\n",
    "dataframe.dropna(how='any')\n",
    "dataframe.dropna(how='any', inplace=True)\n",
    "dataframe.dropna(how='all')\n",
    "dataframe.dropna(how='all', inplace=True)\n",
    "```\n",
    "\n",
    "对特定列操作\n",
    "```\n",
    "dataframe.dropna(subset=[\"col1\",  \"col2\"], how='any')\n",
    "dataframe.dropna(subset=[\"col1\",  \"col2\"], how='all')\n",
    "```\n",
    "\n",
    "### 填充缺失数据\n",
    "fillna()函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对dataframe缺失值和被除数是0的操作\n",
    "```python\n",
    "#nan缺失值\n",
    "df.fillna(0, inplace=True)    # 将df的nan用0代替\n",
    "#在df中进行除法操作时，被除数是0的话，值是inf\n",
    "#替换inf的值\n",
    "import numpy as np\n",
    "df = df.replace(np.inf, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Table\n",
    "Pandas可以用来创建MS Excel样式数据透视表（Pivot Table）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosstab\n",
    "Pivot Table的特殊形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge合并DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame排序sort_values和sort_index\n",
    "Pandas 允许基于多列数据进行简单排列。具体实现如下：\n",
    "```python\n",
    "data_sorted = data.sort_values(['ApplicantIncome','CoapplicantIncome'], ascending=False)\n",
    "data_sorted[['ApplicantIncome','CoapplicantIncome']].head(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set_index(列转索引)reset_index(索引转列)reindex(修改索引)\n",
    "**set_index和reset_index使用的较多，重点理解**\n",
    "\n",
    "### set_index建立索引　　列---->索引\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "#DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
    "　　#key:标签或者数组（Series, Index,np.ndarray）,复合索引则把标签或数组放在list中\n",
    "　　#drop：删除作为新索引的列\n",
    "　　#append ：将列附加到现有的索引\n",
    "　　#inplace ：是否修改Dataframe\n",
    "\n",
    "df = pd.DataFrame({'month': [1, 4, 7, 10],\n",
    "                   'year': [2012, 2014, 2013, 2014],\n",
    "                   'sale': [55, 40, 84, 31]})\n",
    "#列转索引\n",
    "df.set_index('month')\n",
    "\n",
    "#多列转复合索引\n",
    "df.set_index(['year', 'month'])\n",
    "\n",
    "#设置列与另一索引为复合索引\n",
    "df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\n",
    "\n",
    "#使用Series建立索引\n",
    "s = pd.Series([1, 2, 3, 4])\n",
    "df.set_index([s, s**2])\n",
    "```\n",
    "\n",
    "### reset_index重建/删除索引    索引---->列\n",
    "```python\n",
    "#原索引转列，重建递增索引\n",
    "df.reset_index()\n",
    "\n",
    "#删除原索引、重建默认递增索引\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "#行多索引子索引转列多索引的某一层级的列，默认为最高级，若插入其他等级，col_fill为指定最高级索引，若不存在，则创建\n",
    "df.reset_index(level='class', col_level=1, col_fill='genus')\n",
    "```\n",
    "\n",
    "### reset_index修改索引\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#DataFrame.reindex(labels = None，index = None，columns = None，axis = None，method = None，copy = True，level = None，\n",
    "　　　　　　　　　　　 fill_value = nan，limit = None，tolerance = None) \n",
    "    #reindex相当于对DataFrame的架构（index或者column）筛选或者补充，即如果原df存在相应的\n",
    "    ##索引或列，就保留，没有则为NAN，函数有一系列填充NAN的方法（不止固定填充某值,非操作原始数据NAN）\n",
    "\n",
    "\n",
    "index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
    "df = pd.DataFrame({\n",
    "      'http_status': [200,200,404,404,301],\n",
    "      'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
    "       index=index)\n",
    "\n",
    "#重新索引行\n",
    "new_index= ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10','Chrome']\n",
    "df.reindex(new_index, fill_value='missing')\n",
    "\n",
    "#重新索引列\n",
    "df.reindex(columns=['http_status', 'user_agent'])    \n",
    "\n",
    "#展示对索引中产生的NAN的填充功能\n",
    "date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
    "df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},index=date_index)\n",
    "date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
    "df2.reindex(date_index2)\n",
    "#第一个有效值以填充之前的NaN值\n",
    "df2.reindex(date_index2, method='bfill')\n",
    "\n",
    "#.reindex_like\n",
    "#等价于.reindex(index=other.index, columns=other.columns,...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Cut 函数进行分箱\n",
    "有时将数值数据聚合在一起会更有意义。例如，如果我们要根据一天中的某个时间段（单位：分钟）建立交通流量模型模型（以路上的汽车为统计目标）。与具体的分钟数相比，对于交通流量预测而言一天中的具体时间段则更为重要，如“早上”、 “下午”、“傍晚”、“夜晚”、“深夜（Late Night）”。以这种方式建立交通流量模型则更为直观且避免了过拟合情况的发生。\n",
    "\n",
    "下面的例子中定义了一个简单的可重用函数，该函数可以非常轻松地实现任意变量的分箱功能。\n",
    "```python\n",
    "#Binning:\n",
    "def binning(col, cut_points, labels=None):\n",
    "  #Define min and max values:\n",
    "  minval = col.min()\n",
    "  maxval = col.max()\n",
    " \n",
    "  #create list by adding min and max to cut_points\n",
    "  break_points = [minval] + cut_points + [maxval]\n",
    " \n",
    "  #if no labels provided, use default labels 0 ... (n-1)\n",
    "  if not labels:\n",
    "    labels = range(len(cut_points)+1)\n",
    " \n",
    "  #Binning using cut function of pandas\n",
    "  colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n",
    "  return colBin\n",
    " \n",
    "#Binning age:\n",
    "cut_points = [90,140,190]\n",
    "labels = [\"low\",\"medium\",\"high\",\"very high\"]\n",
    "data[\"LoanAmount_Bin\"] = binning(data[\"LoanAmount\"], cut_points, labels)\n",
    "print pd.value_counts(data[\"LoanAmount_Bin\"], sort=False)\n",
    "```\n",
    "\n",
    "Read More: Pandas Reference (cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为名称变量编码\n",
    "通常我们会遇到需要对名称变量进行分类的情况。可能的原因如下：\n",
    "\n",
    "* 1. 一些算法（如逻辑回归算法）要求输入参数全部为数字。因此名义变量多需要编码为0, 1….(n-1)。\n",
    "\n",
    "* 2. 有时同一种分类可以表示为两种形式。如温度可能被记录为“高（High）”、“中（Medium）”、“低（Low）”、“高（H）”、“低（low）”。在这里，“高（High）”和“高（H）”都表示同一种分类。类似地在“低（Low）”和“低（low）”的表示方法中仅存在大小写的区别。但 python 将会将它们视为不同的温度水平。\n",
    "\n",
    "* 3.一些分类的出现频率可能较低，因此将这些分类归为一类不失为一个好主意。\n",
    "\n",
    "下面的例子中定义了一个通用函数，该函数使用字典作为输入，并利用 Pandas 模块的‘replace’函数对字典值进行编码。\n",
    "```python\n",
    "#Define a generic function using Pandas replace function\n",
    "def coding(col, codeDict):\n",
    "  colCoded = pd.Series(col, copy=True)\n",
    "  for key, value in codeDict.items():\n",
    "    colCoded.replace(key, value, inplace=True)\n",
    "  return colCoded\n",
    " \n",
    "#Coding LoanStatus as Y=1, N=0:\n",
    "print 'Before Coding:'\n",
    "print pd.value_counts(data[\"Loan_Status\"])\n",
    "data[\"Loan_Status_Coded\"] = coding(data[\"Loan_Status\"], {'N':0,'Y':1})\n",
    "print 'nAfter Coding:'\n",
    "print pd.value_counts(data[\"Loan_Status_Coded\"])\n",
    "```\n",
    "\n",
    "**ps:高版本已经有了分类类型，无需自己实现**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame重命名列\n",
    "* **部分重命名**\n",
    "\n",
    "columns = dict，使用字典类型的数据对列进行重命名。\n",
    "```python\n",
    "dataframe.rename(columns = {\"old_name\": \"new_name\"})\n",
    "dataframe.rename(columns = {\"old1\": \"new1\", \"old2\":\"new2\"},  inplace=True)\n",
    "```\n",
    "\n",
    "* **全部重命名**\n",
    "\n",
    "columns = new_columns，新列名的长度必须与旧列名一致。\n",
    "```python\n",
    "new_col = ['new1', 'new2',... , 'newn']\n",
    "dataframe.columns = new_col\n",
    "```\n",
    "\n",
    "* **读取文件的时候重命名**\n",
    "\n",
    "names = new_col，可以在读取文件的时候，给出新列名。\n",
    "```python\n",
    "pd.read_csv('data', names = new_col, header=0)\n",
    "```\n",
    "\n",
    "* **使用str**\n",
    "\n",
    "```python\n",
    "dataframe.columns = dataframe.columns.str.replace('' '', ''_'')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入和写出表单数据\n",
    "### 读入数据\n",
    "* pandas.read_csv()  \n",
    "从文件，URL，文件型对象中加载带分隔符的数据。默认分隔符为'',\"  \n",
    "* pandas.read_table()  \n",
    "从文件，URL，文件型对象中加载带分隔符的数据。默认分隔符为\"\\t\"  \n",
    "\n",
    "**参数：** \n",
    "\n",
    "\n",
    "* **分隔符参数**：sep=\n",
    "read_csv和read_table的区别在于separator分隔符。csv是逗号分隔值(Comma-Separated Values)，仅能正确读入以 \",\" 分割的数据。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  sep=\",\")`\n",
    "\n",
    "* **是否读取文本数据的header**：header=\n",
    "headers = None表示使用默认分配的列名，一般用在读取没有header的数据文件。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  header=None)`\n",
    "\n",
    "* **为文本的数据加上列名**： names=\n",
    "names = user_cols ，自定义列名为user_cols。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  names = user_cols)`\n",
    "\n",
    "* **明确索引值**： index_col=\n",
    "index_col = user_col，明确表示要将user_col放入索引位置。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  names = names,  index_col = user_col)`\n",
    "\n",
    "也可以将多个列都放入索引位置，做成层次化索引。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  names = names,  index_col = [\"col1\",  \"col2\"])`\n",
    "\n",
    "* **跳过指定行**： skiprows=\n",
    "skiprows = row_list_to_skipped，可以用与跳过非有效数据如注释等情形下。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  skiprows = [row1,  row2,..., rown])`\n",
    "\n",
    "* **缺失值处理**：na_values=\n",
    "na_values= [\"null\"]，用null字符替换缺失值。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  na_values= [\"null\"])`\n",
    "\n",
    "* **尝试将数据解析为日期**：parse_dates=\n",
    "parse_dates = True，尝试解析所有可能为日期类型的列。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  parse_dates = True)`\n",
    "\n",
    "parse_dates = [1, 2]，尝试解析给定列为日期类型的列。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  parse_dates = [1, 2])`\n",
    "\n",
    "* **指定需要读取的行数**：nrows=\n",
    "nrows = 100， 指定读取前100行数据。\n",
    "\n",
    "`pd.read_table(\"ex1.csv\",  nrows = 100)`\n",
    "\n",
    "\n",
    "### 写出数据\n",
    "* pandas.to_csv()\n",
    "\n",
    "* pandas.to_table()\n",
    "\n",
    "参数和读入数据类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将不同Dataframe写在一个Excel的不同Sheet,或添加到已有Excel的不同Sheet（同名Sheet会覆盖）\n",
    "```python\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "#在单个文件中不同df写入对应不同的的工作表\n",
    "with ExcelWriter('path_to_file.xlsx') as writer:\n",
    "    df1.to_excel(writer, sheet_name='Sheet1')\n",
    "    df2.to_excel(writer, sheet_name='Sheet2')\n",
    "\n",
    "#附加到已有的Excel文件\n",
    "with ExcelWriter('path_to_file.xlsx', mode='a') as writer:\n",
    "    df.to_excel(writer, sheet_name='Sheet3')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas 数据类型转换\n",
    "这里有一篇比较详细的文章：https://www.cnblogs.com/onemorepoint/p/9404753.html\n",
    "\n",
    "### 使用df.astype()强制类型转换\n",
    "```python\n",
    "# 这样的操作并没有改变原始的数据\n",
    "df['Customer Number'].astype(\"int\")\n",
    "\n",
    "# 想要真正的改变数据框，通常需要通过赋值来进行，比如\n",
    "df[\"Customer Number\"] = df[\"Customer Number\"].astype(\"int\")\n",
    "```\n",
    "\n",
    "### 使用pd.to_numeric() 转换成适当数值类型\n",
    "```python\n",
    "# pandas中pd.to_numeric()处理Jan Units中的数据,errors='coerce'转换错误会用nan替换\n",
    "pd.to_numeric(df[\"Jan Units\"],errors='coerce').fillna(0)\n",
    "```\n",
    "\n",
    "### 使用pd.to_datatime() 转换日期\n",
    "```python\n",
    "#利用pd.to_datatime()将年月日进行合并\n",
    "pd.to_datetime(df[['Month', 'Day', 'Year']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何丢弃指定Series和DataFrame轴上的项\n",
    "当想将原数据更改，需要加上inplace参数\n",
    "\n",
    "### Series\n",
    "* **drop单行**\n",
    "```python\n",
    "series.drop(\"row_to_drop\",)\n",
    "```\n",
    "\n",
    "* **drop多行**\n",
    "```python\n",
    "series.drop( [row1, row2,..., rown])\n",
    "```\n",
    "\n",
    "### DataFrame\n",
    "* **去掉行（axis=0）**\n",
    "\n",
    "drop单行:给出需要删除的行名，可以不设置axis，默认为0\n",
    "```python\n",
    "dataframe.drop( [row_to_drop],  axis=0)\n",
    "```\n",
    "drop多行:给出需要删除的行名列表，可以不设置axis，默认为0\n",
    "```python\n",
    "dataframe.drop( [row1, row2,...,rown],  axis=0, inplace=True)\n",
    "```\n",
    "\n",
    "* **去掉列（axis=1）**\n",
    "\n",
    "drop单列:给出需要删除的列名，同时设置axis=1\n",
    "```python\n",
    "dataframe.drop(\"col_to_drop\",  axis=1)\n",
    "dataframe.drop(\"col_to_drop\",  axis=1, inplace=True)\n",
    "```\n",
    "drop多列:给出需要删除的列名列表，同时设置axis=1\n",
    "```python\n",
    "dataframe.drop( [\"col1\", \"col2\",..., \"coln\"],  axis=1)\n",
    "dataframe.drop( [\"col1\", \"col2\",..., \"coln\"],  axis=1, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
